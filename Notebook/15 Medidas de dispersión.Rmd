---
title: "Medidas de dispersion"
author: "Daniel"
date: "10-11-2019"
output: html_document
---

# Medidas de dispersión

Las *medidas de dispersión* evalúan lo dispersos que están los datos. Algunas de las más importantes son: 
* El *rango o recorrido*, que es la diferencia entre el máximo y el mínimo de las observaciones.
* El *rango intercuartílico*, que es la diferencia entre el tercer y primer cuartil, $Q_{0.75}- Q_{0.25}$.
* La *varianza*, a la que denotaremos por $s^2$,, es la media aritmetica de las diferencias al cuadrado entre los datos $x_i$ y la media aritmética de las observaciones, $\bar{x}$

$$s^2 = \frac{{\sum_{j=1}^{n}(x_j-\bar{x})^2}}{n} = \frac{{\sum_{j=1}^{k}n_j(X_j-\bar{x})^2}}{n}  =
{\sum_{j=1}^{k}f_i(X_j-\bar{x})^2}$$

* La *desviación típica* es la raíz cuadrada positiva de la varianza, $s = \sqrt{s^2}$
* La *varianza muestral* es la corrección de la varianza. La denotamos por $\tilde{s^2}$ y se corresponde con

$$\tilde{s}^2 = \frac{n}{n-1}s^2 = \frac{\sum_{j=1}^{n}(x_i-\bar{x})^2}{n-1}$$

* La *desviación típica muestral*, que es la raíz cuadrada positiva de la varianza muestral, $\tilde{s}^2 = \sqrt{\tilde{s}^2}$

## Propiedades de la varianza

* $s^2 \geq0$. Esto se debe a que, por definición, es una suma de cuadrados de números reales.
* $s^2 = 0 \Longrightarrow x_j-\bar{x} = 0$ $\forall_j=1,...,n$. En consecuencia, si $s^2=0$, entonces todos los datos son iguales.
* $s^2 = \frac{\sum_{j=1}^{n}x_{j}^{2}}{n}-\bar{x}^2$. Es decir, la varianza es la media de los cuadrados de los datos menos el cuadrado de la media aritmética.

## Varianza y varianza muetral

La diferencia entre ambas definiciones viene por la interrelación entre la estadística descriptiva y la inferencial.
Por un lado, es normal medir como varían los datos cuantitativos mediante su varianza definida como la media aritmética de las distancias al cuadrado de los datos a su valor medio. No obstante, por otro lado, el conjunto de nuestras observaciones, por lo normal, será una muestra de una población mucho mayor y nos interesará estimar entre otras muchas cosas su variabilidad.
La varianza de una muestra suele dar valores más pequeños que la varianza de la población, mientras que la varianza muestral tiende a dar valores alrededor de la varianza de la población.

Esta corrección, para el caso de una muestra grande no es notable. Dividir $n$ entre $n-1$ en el caso de $n$ ser grande no significa una gran diferencia y aún menos si tenemos en cuenta que lo que tratamos es de estimar la varianza de la población, no de calcularla de forma exacta.

En cambio, si la muestra es relativamente pequeña (digamos $n <30$), entonces la varianza muestral de la muestra aproxima significativamente mejor la varianza de la población que la varianza.

La diferencia entre la desviación típica y desviación típica muestral es análoga.

Con **R**, calcularemos la varianza y la desviación típica **muestrales**. Con lo cual, si queremos calcular las que no son muestrales, tendremos que multiplicarlas por $\frac{n-1}{n}$, donde $n$ es el tamaño de la muestra.


Varianza y dispersión típica

*Todo lo muestral lleva tilde.*

```{r}
dados2
```

**Rango**
```{r}
diff(range(dados2))
```

**Rango intercuartilico**

```{r}
IQR(dados2)
```

**Varianza Muestral**
```{r}
var(dados2)
```

**Desviación típica muestral**
```{r}
sd(dados2)

```


**Varianza**
```{r}
n = length(dados2)
var(dados2)*(n-1)/n

```


**Desviación tipica**
```{r}
sd(dados2)*sqrt((n-1)/n)
```














